{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-07T01:23:00.469347Z","iopub.status.busy":"2024-07-07T01:23:00.468712Z","iopub.status.idle":"2024-07-07T01:23:10.158443Z","shell.execute_reply":"2024-07-07T01:23:10.157508Z","shell.execute_reply.started":"2024-07-07T01:23:00.469317Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for i,filename in enumerate(filenames):\n","        print(os.path.join(dirname, filename))\n","        if i>=10:\n","            break\n","        \n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:10.160524Z","iopub.status.busy":"2024-07-07T01:23:10.160103Z","iopub.status.idle":"2024-07-07T01:23:13.469921Z","shell.execute_reply":"2024-07-07T01:23:13.469148Z","shell.execute_reply.started":"2024-07-07T01:23:10.160497Z"},"trusted":true},"outputs":[],"source":["try:\n","    from torchinfo import summary\n","except:\n","    print(\"[INFO] Couldn't find torchinfo ... installing it.\")\n","    !pip install -q torchinfo\n","    from torchinfo import summary"]},{"cell_type":"markdown","metadata":{},"source":["### Content of the notebook:\n","1. Beauty rate using pretrained model on pytorch (YOLO?)\n","2. denoise, refine the photo\n","3. generate ID photo"]},{"cell_type":"markdown","metadata":{},"source":["#### 1. Import dataset, preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:13.471555Z","iopub.status.busy":"2024-07-07T01:23:13.471069Z","iopub.status.idle":"2024-07-07T01:23:13.591134Z","shell.execute_reply":"2024-07-07T01:23:13.590374Z","shell.execute_reply.started":"2024-07-07T01:23:13.471518Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm\n","\n","BASE_DIR = \"/kaggle/input/scut-fbp5500-v2-facial-beauty-scores\"\n","data=[]\n","\n","with open(f'{BASE_DIR}/labels.txt', 'r',encoding='utf-8') as labels_file:\n","    labels = labels_file.readlines()\n","#     print(labels)\n","    for label in tqdm(labels):\n","        row = label.rstrip('\\n').split(' ')\n","        data.append(row)\n","        \n","df=pd.DataFrame(data, columns =['filename','beauty_rate'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:13.592385Z","iopub.status.busy":"2024-07-07T01:23:13.592115Z","iopub.status.idle":"2024-07-07T01:23:15.104093Z","shell.execute_reply":"2024-07-07T01:23:15.103109Z","shell.execute_reply.started":"2024-07-07T01:23:13.592362Z"},"trusted":true},"outputs":[],"source":["import torchvision\n","IMAGE_DIR = BASE_DIR +'/Images/Images/'\n","\n","image_tensor = torchvision.io.read_image(IMAGE_DIR+df.iloc[1,0])\n","image_tensor.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.106903Z","iopub.status.busy":"2024-07-07T01:23:15.106507Z","iopub.status.idle":"2024-07-07T01:23:15.11426Z","shell.execute_reply":"2024-07-07T01:23:15.113297Z","shell.execute_reply.started":"2024-07-07T01:23:15.106876Z"},"trusted":true},"outputs":[],"source":["## sample a few images to show\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import math\n","import torch\n","\n","\n","def plot_beauty(df, img_dir, num=5 ,random_seed=42):\n","    fig = plt.figure(figsize=(9,9))\n","    rows, cols = math.ceil(num/3) ,3\n","    torch.manual_seed(random_seed)\n","    for i in range(num):\n","        id = torch.randint(0,len(df),size=[1]).item()\n","        img_path, label = f'{img_dir}/{df.iloc[id,0]}', df.iloc[id,1]\n","        fig.add_subplot(rows, cols, i+1)\n","        im = Image.open(img_path)\n","        plt.imshow(im)\n","        plt.title('beauty label:'+label)\n","        plt.axis(False)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.115893Z","iopub.status.busy":"2024-07-07T01:23:15.115614Z","iopub.status.idle":"2024-07-07T01:23:15.915811Z","shell.execute_reply":"2024-07-07T01:23:15.914929Z","shell.execute_reply.started":"2024-07-07T01:23:15.11587Z"},"trusted":true},"outputs":[],"source":["plot_beauty(df, IMAGE_DIR, random_seed=68)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.917095Z","iopub.status.busy":"2024-07-07T01:23:15.916853Z","iopub.status.idle":"2024-07-07T01:23:15.924426Z","shell.execute_reply":"2024-07-07T01:23:15.923562Z","shell.execute_reply.started":"2024-07-07T01:23:15.917073Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader, Subset\n","import os\n","\n","\n","class FaceData(Dataset):\n","    def __init__(self, df, img_dir, transform):\n","        self.df = df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        filename, label = self.df.iloc[idx].values\n","        img_path = os.path.join(self.img_dir, filename)\n","        \n","        image = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, torch.tensor(float(label), dtype=torch.float32), img_path\n","#     def get_path_by_idx(self, idx):\n","#         filename, label = self.df.iloc[idx].values\n","#         img_path = os.path.join(self.img_dir, filename)\n","#         return img_path\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.926026Z","iopub.status.busy":"2024-07-07T01:23:15.925718Z","iopub.status.idle":"2024-07-07T01:23:15.933333Z","shell.execute_reply":"2024-07-07T01:23:15.932479Z","shell.execute_reply.started":"2024-07-07T01:23:15.926Z"},"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","\n","transform1 = transforms.Compose([\n","    transforms.Resize((128,128)),\n","    transforms.ToTensor()\n","])\n","\n","faceds = FaceData(df, f'{BASE_DIR}/Images/Images', transform = transform1)"]},{"cell_type":"markdown","metadata":{},"source":["#### train / test split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.93471Z","iopub.status.busy":"2024-07-07T01:23:15.934433Z","iopub.status.idle":"2024-07-07T01:23:15.942681Z","shell.execute_reply":"2024-07-07T01:23:15.941934Z","shell.execute_reply.started":"2024-07-07T01:23:15.934688Z"},"trusted":true},"outputs":[],"source":["val_size = 0.2\n","indices = list(range(len(df)))\n","\n","np.random.shuffle(indices)\n","split = int(np.floor(val_size * len(df)))\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","train_ds = Subset(faceds, train_indices)\n","val_ds = Subset(faceds, val_indices)\n","\n","train_loader = DataLoader(train_ds, batch_size=32, shuffle = True)\n","val_loader = DataLoader(val_ds, batch_size=32, shuffle = True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Transfer learning from pytorch keypoint detection model\n","https://pytorch.org/vision/stable/models.html#keypoint-detection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:15.94426Z","iopub.status.busy":"2024-07-07T01:23:15.943684Z","iopub.status.idle":"2024-07-07T01:23:21.353382Z","shell.execute_reply":"2024-07-07T01:23:21.352311Z","shell.execute_reply.started":"2024-07-07T01:23:15.944234Z"},"trusted":true},"outputs":[],"source":["from torchvision.models.detection import keypointrcnn_resnet50_fpn, KeypointRCNN_ResNet50_FPN_Weights\n","from torchvision.io import read_image\n","\n","person_int = read_image(IMAGE_DIR+df.iloc[8,0])\n","\n","weights = KeypointRCNN_ResNet50_FPN_Weights.DEFAULT\n","transforms = weights.transforms()\n","\n","person_float = transforms(person_int)\n","\n","model = keypointrcnn_resnet50_fpn(weights=weights, progress=False)\n","model = model.eval()\n","\n","outputs = model([person_float])\n","print(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.354729Z","iopub.status.busy":"2024-07-07T01:23:21.354461Z","iopub.status.idle":"2024-07-07T01:23:21.361716Z","shell.execute_reply":"2024-07-07T01:23:21.360778Z","shell.execute_reply.started":"2024-07-07T01:23:21.354707Z"},"trusted":true},"outputs":[],"source":["kpts = outputs[0]['keypoints']\n","scores = outputs[0]['scores']\n","\n","print(kpts)\n","print(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.362932Z","iopub.status.busy":"2024-07-07T01:23:21.362688Z","iopub.status.idle":"2024-07-07T01:23:21.384672Z","shell.execute_reply":"2024-07-07T01:23:21.38374Z","shell.execute_reply.started":"2024-07-07T01:23:21.36291Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms.functional as F\n","\n","def show(imgs):\n","    if not isinstance(imgs, list):\n","        imgs = [imgs]\n","    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n","    for i, img in enumerate(imgs):\n","        img = img.detach()\n","        img = F.to_pil_image(img)\n","        axs[0, i].imshow(np.asarray(img))\n","        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.385877Z","iopub.status.busy":"2024-07-07T01:23:21.385652Z","iopub.status.idle":"2024-07-07T01:23:21.395166Z","shell.execute_reply":"2024-07-07T01:23:21.394255Z","shell.execute_reply.started":"2024-07-07T01:23:21.385858Z"},"trusted":true},"outputs":[],"source":["detect_threshold = 0.75\n","idx = torch.where(scores > detect_threshold)\n","keypoints = kpts[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.400279Z","iopub.status.busy":"2024-07-07T01:23:21.399634Z","iopub.status.idle":"2024-07-07T01:23:21.637976Z","shell.execute_reply":"2024-07-07T01:23:21.63717Z","shell.execute_reply.started":"2024-07-07T01:23:21.400254Z"},"trusted":true},"outputs":[],"source":["from torchvision.utils import draw_keypoints\n","\n","res = draw_keypoints(person_int, keypoints, colors=\"blue\",radius=3)\n","show(res)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dir(model)\n","model.state_dict\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.649622Z","iopub.status.busy":"2024-07-07T01:23:21.649308Z","iopub.status.idle":"2024-07-07T01:23:21.655021Z","shell.execute_reply":"2024-07-07T01:23:21.654192Z","shell.execute_reply.started":"2024-07-07T01:23:21.649596Z"},"trusted":true},"outputs":[],"source":["# for idx, param in enumerate(model.parameters()):\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:21.656805Z","iopub.status.busy":"2024-07-07T01:23:21.656249Z","iopub.status.idle":"2024-07-07T01:23:25.194199Z","shell.execute_reply":"2024-07-07T01:23:25.193343Z","shell.execute_reply.started":"2024-07-07T01:23:21.656773Z"},"trusted":true},"outputs":[],"source":["# Print a summary using torchinfo (uncomment for actual output)\n","summary(model=model, \n","        input_size=(32, 3,128,128), # make sure this is \"input_size\", not \"input_shape\"\n","        # col_names=[\"input_size\"], # uncomment for smaller output\n","        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n","        col_width=20,\n","        row_settings=[\"var_names\"]\n",") "]},{"cell_type":"markdown","metadata":{},"source":["#### Use pretrained model on transformer, ViT to do image classification\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:23:25.195776Z","iopub.status.busy":"2024-07-07T01:23:25.195433Z","iopub.status.idle":"2024-07-07T01:23:38.264525Z","shell.execute_reply":"2024-07-07T01:23:38.263545Z","shell.execute_reply.started":"2024-07-07T01:23:25.195742Z"},"trusted":true},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:01.033659Z","iopub.status.busy":"2024-07-07T01:25:01.032998Z","iopub.status.idle":"2024-07-07T01:25:15.815752Z","shell.execute_reply":"2024-07-07T01:25:15.814826Z","shell.execute_reply.started":"2024-07-07T01:25:01.033627Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from transformers import AutoImageProcessor, ViTForImageClassification, ViTFeatureExtractor\n","\n","modelVit = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n","feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n","image_processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n","\n","\n","# Step 2: Modify the Model Architecture\n","class ModifiedViT(nn.Module):\n","    def __init__(self, base_model):\n","        super(ModifiedViT, self).__init__()\n","        self.base_model = base_model\n","        self.fc1 = nn.Linear(base_model.config.hidden_size, 256)\n","        self.dropout1 = nn.Dropout(0.5)\n","        self.classifier = nn.Linear(256, 1)\n","\n","    def forward(self, x):\n","        x = self.base_model.vit(x).last_hidden_state[:, 0]\n","        x = self.fc1(x)\n","        x = nn.ReLU()(x)\n","        x = self.dropout1(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:15.817692Z","iopub.status.busy":"2024-07-07T01:25:15.817171Z","iopub.status.idle":"2024-07-07T01:25:15.827701Z","shell.execute_reply":"2024-07-07T01:25:15.825951Z","shell.execute_reply.started":"2024-07-07T01:25:15.817666Z"},"trusted":true},"outputs":[],"source":["modifiedVit = ModifiedViT(modelVit)\n","\n","print(\"Number of GPUs available:\", torch.cuda.device_count())\n","\n","if torch.cuda.device_count() > 1:\n","    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n","    ModifiedViT = nn.DataParallel(ModifiedViT)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:21.990008Z","iopub.status.busy":"2024-07-07T01:25:21.989179Z","iopub.status.idle":"2024-07-07T01:25:21.995352Z","shell.execute_reply":"2024-07-07T01:25:21.99442Z","shell.execute_reply.started":"2024-07-07T01:25:21.989974Z"},"trusted":true},"outputs":[],"source":["## freeze the parameters of pretrained ViT\n","\n","modifiedVit.base_model.classifier = None\n","\n","for param in modifiedVit.base_model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:24.656847Z","iopub.status.busy":"2024-07-07T01:25:24.656238Z","iopub.status.idle":"2024-07-07T01:25:24.722854Z","shell.execute_reply":"2024-07-07T01:25:24.721983Z","shell.execute_reply.started":"2024-07-07T01:25:24.656815Z"},"trusted":true},"outputs":[],"source":["modifiedVit\n","summary(modifiedVit)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:31.447695Z","iopub.status.busy":"2024-07-07T01:25:31.446767Z","iopub.status.idle":"2024-07-07T01:25:31.45406Z","shell.execute_reply":"2024-07-07T01:25:31.453215Z","shell.execute_reply.started":"2024-07-07T01:25:31.447661Z"},"trusted":true},"outputs":[],"source":["image_processor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-07-07T01:23:38.597262Z","iopub.status.idle":"2024-07-07T01:23:38.597583Z","shell.execute_reply":"2024-07-07T01:23:38.597439Z","shell.execute_reply.started":"2024-07-07T01:23:38.597426Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:40.268552Z","iopub.status.busy":"2024-07-07T01:25:40.268197Z","iopub.status.idle":"2024-07-07T01:25:40.275448Z","shell.execute_reply":"2024-07-07T01:25:40.274445Z","shell.execute_reply.started":"2024-07-07T01:25:40.268522Z"},"trusted":true},"outputs":[],"source":["## construct transformation for images\n","\n","from torchvision.transforms import (\n","    CenterCrop,\n","    Compose,\n","    Normalize,\n","    RandomHorizontalFlip,\n","    RandomResizedCrop,\n","    Resize,\n","    ToTensor,\n",")\n","\n","normalize =Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n","if \"height\" in image_processor.size:\n","    size=(image_processor.size[\"height\"],image_processor.size[\"width\"])\n","    \n","    crop_size = size\n","    max_size =None\n","    \n","\n","train_transforms = Compose(\n","    [\n","        RandomResizedCrop(crop_size),\n","        RandomHorizontalFlip(p=0.4),\n","        ToTensor(),\n","        normalize,\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:25:43.405893Z","iopub.status.busy":"2024-07-07T01:25:43.405053Z","iopub.status.idle":"2024-07-07T01:25:43.410515Z","shell.execute_reply":"2024-07-07T01:25:43.409606Z","shell.execute_reply.started":"2024-07-07T01:25:43.405862Z"},"trusted":true},"outputs":[],"source":["val_transforms = Compose(\n","    [\n","        Resize(size),\n","        CenterCrop(crop_size),\n","        ToTensor(),\n","        normalize,\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:27:55.430361Z","iopub.status.busy":"2024-07-07T01:27:55.429979Z","iopub.status.idle":"2024-07-07T01:27:55.443205Z","shell.execute_reply":"2024-07-07T01:27:55.442251Z","shell.execute_reply.started":"2024-07-07T01:27:55.430328Z"},"trusted":true},"outputs":[],"source":["## dataset and dataloader \n","\n","\n","val_size = 0.2\n","indices = list(range(len(df)))\n","\n","np.random.shuffle(indices)\n","split = int(np.floor(val_size * len(df)))\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","\n","# train_ds = Subset(faceds, train_indices)\n","# val_ds = Subset(faceds, val_indices)\n","\n","train_ds = FaceData(df.iloc[train_indices,:], f'{BASE_DIR}/Images/Images', transform = train_transforms)\n","val_ds = FaceData(df.iloc[val_indices,:], f'{BASE_DIR}/Images/Images', transform = val_transforms)\n","\n","\n","train_loader = DataLoader(train_ds, batch_size=32, shuffle = True)\n","val_loader = DataLoader(val_ds, batch_size=32, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:27:59.326195Z","iopub.status.busy":"2024-07-07T01:27:59.325154Z","iopub.status.idle":"2024-07-07T01:27:59.334934Z","shell.execute_reply":"2024-07-07T01:27:59.333792Z","shell.execute_reply.started":"2024-07-07T01:27:59.326138Z"},"trusted":true},"outputs":[],"source":["type(df.iloc[train_indices,:])\n","print( f'{BASE_DIR}/Images/Images')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:28:15.445562Z","iopub.status.busy":"2024-07-07T01:28:15.444683Z","iopub.status.idle":"2024-07-07T01:28:15.471063Z","shell.execute_reply":"2024-07-07T01:28:15.4702Z","shell.execute_reply.started":"2024-07-07T01:28:15.445528Z"},"trusted":true},"outputs":[],"source":["train_ds[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:28:22.905531Z","iopub.status.busy":"2024-07-07T01:28:22.904864Z","iopub.status.idle":"2024-07-07T01:28:35.130408Z","shell.execute_reply":"2024-07-07T01:28:35.129401Z","shell.execute_reply.started":"2024-07-07T01:28:22.905497Z"},"trusted":true},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:28:35.1328Z","iopub.status.busy":"2024-07-07T01:28:35.132497Z","iopub.status.idle":"2024-07-07T01:30:01.33007Z","shell.execute_reply":"2024-07-07T01:30:01.328997Z","shell.execute_reply.started":"2024-07-07T01:28:35.132772Z"},"trusted":true},"outputs":[],"source":["!wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:30:04.517324Z","iopub.status.busy":"2024-07-07T01:30:04.516484Z","iopub.status.idle":"2024-07-07T01:30:37.907361Z","shell.execute_reply":"2024-07-07T01:30:37.906457Z","shell.execute_reply.started":"2024-07-07T01:30:04.517289Z"},"trusted":true},"outputs":[],"source":["import wandb\n","import random\n","\n","# start a new wandb run to track this script\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"facial_beauty\",\n","    \n","    id =\"facial-240706\",\n","    \n","    resume = \"allow\",\n","\n","    # track hyperparameters and run metadata\n","    config={\n","    \"learning_rate\": 0.001,\n","    \"architecture\": \"ViT\",\n","    \"dataset\": \"facial_beauty\",\n","    \"epochs\": 5,\n","    \"batch_size\": 32,\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-07-07T01:23:38.613257Z","iopub.status.idle":"2024-07-07T01:23:38.613593Z","shell.execute_reply":"2024-07-07T01:23:38.613445Z","shell.execute_reply.started":"2024-07-07T01:23:38.613432Z"},"trusted":true},"outputs":[],"source":["# # Log hyperparameters\n","# wandb.config = {\n","#     \"learning_rate\": 0.001,\n","#     \"epochs\": 5,\n","#     \"batch_size\": 32\n","# }\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:31:45.820731Z","iopub.status.busy":"2024-07-07T01:31:45.820376Z","iopub.status.idle":"2024-07-07T01:38:46.952645Z","shell.execute_reply":"2024-07-07T01:38:46.95157Z","shell.execute_reply.started":"2024-07-07T01:31:45.820703Z"},"trusted":true},"outputs":[],"source":["# Step 4: Fine-Tune the Model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","modifiedVit.to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(modifiedVit.parameters(), lr=0.001)\n","\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    modifiedVit.train()\n","    running_loss = 0.0\n","    for images, labels, _ in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = modifiedVit(images)\n","        loss = criterion(outputs.squeeze(), labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}')\n","    \n","    # Log the loss\n","    wandb.log({\"train_loss\": running_loss / len(train_loader.dataset)})\n","    \n","\n","    modifiedVit.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for images, labels, _ in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = modifiedVit(images)\n","            loss = criterion(outputs.squeeze(), labels)\n","            val_loss += loss.item() * images.size(0)\n","\n","    val_loss /= len(val_loader.dataset)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Val Loss: {val_loss:.4f}')\n","    # Log the loss\n","    wandb.log({\"val_loss\": val_loss / len(val_loader.dataset)})\n","    \n","\n","print(\"Training complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:45:15.222721Z","iopub.status.busy":"2024-07-07T01:45:15.222315Z","iopub.status.idle":"2024-07-07T01:45:15.617678Z","shell.execute_reply":"2024-07-07T01:45:15.61669Z","shell.execute_reply.started":"2024-07-07T01:45:15.222691Z"},"trusted":true},"outputs":[],"source":["# Set the model to evaluation mode\n","modifiedVit.eval()\n","\n","index = 0\n","# Get the image and label\n","images, labels, _ = next(iter(val_loader))\n","image = images[index]\n","label = labels[index]\n","\n","# Add a batch dimension (required for the model)\n","image = image.unsqueeze(0)\n","\n","# Move the image and the model to the same device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","image = image.to(device)\n","model = model.to(device)\n","\n","# Make the prediction\n","with torch.no_grad():\n","    output = modifiedVit(image)\n","# If the output is a tensor, convert it to a list/float\n","predicted_value = output.item()\n","\n","# Display the image and the prediction\n","image = image.squeeze().cpu().numpy().transpose((1, 2, 0))\n","plt.imshow(image)\n","plt.title(f\"Predicted: {predicted_value:.4f}, Actual: {label.item():.4f}\")\n","plt.axis('off')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T01:45:36.863951Z","iopub.status.busy":"2024-07-07T01:45:36.863599Z","iopub.status.idle":"2024-07-07T01:45:36.871963Z","shell.execute_reply":"2024-07-07T01:45:36.870888Z","shell.execute_reply.started":"2024-07-07T01:45:36.863923Z"},"trusted":true},"outputs":[],"source":["len(val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T02:35:52.784114Z","iopub.status.busy":"2024-07-07T02:35:52.783278Z","iopub.status.idle":"2024-07-07T02:36:08.863815Z","shell.execute_reply":"2024-07-07T02:36:08.86267Z","shell.execute_reply.started":"2024-07-07T02:35:52.784082Z"},"trusted":true},"outputs":[],"source":["val_pred_lst1, val_pred_lst2, val_pred_lst3 = [],[],[]\n","\n","\n","for i in tqdm(range(len(val_loader))):\n","    images, labels, paths = next(iter(val_loader))\n","#     print(labels)\n","#     print(paths)\n","\n","    # Move the image and the model to the same device (CPU or GPU)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    images = images.to(device)\n","    model = model.to(device)\n","\n","    # Make the prediction\n","    with torch.no_grad():\n","        outputs = modifiedVit(images)\n","\n","        outputs = torch.transpose(outputs, 0,1)\n","#         print(outputs)\n","\n","        outputs = outputs.squeeze().to('cpu')\n","        print(outputs)\n","    \n","    val_pred_lst1 += list(paths)\n","    val_pred_lst2 += labels.tolist()\n","    val_pred_lst3 += outputs.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T02:36:13.962686Z","iopub.status.busy":"2024-07-07T02:36:13.962019Z","iopub.status.idle":"2024-07-07T02:36:13.97136Z","shell.execute_reply":"2024-07-07T02:36:13.967985Z","shell.execute_reply.started":"2024-07-07T02:36:13.96265Z"},"trusted":true},"outputs":[],"source":["val_pred = pd.DataFrame({\n","    'img_path': val_pred_lst1,\n","    'label': val_pred_lst2,\n","    'pred': val_pred_lst3\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T02:36:16.555197Z","iopub.status.busy":"2024-07-07T02:36:16.554829Z","iopub.status.idle":"2024-07-07T02:36:16.567941Z","shell.execute_reply":"2024-07-07T02:36:16.567006Z","shell.execute_reply.started":"2024-07-07T02:36:16.555147Z"},"trusted":true},"outputs":[],"source":["val_pred.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T02:39:33.123518Z","iopub.status.busy":"2024-07-07T02:39:33.122773Z","iopub.status.idle":"2024-07-07T02:39:33.132985Z","shell.execute_reply":"2024-07-07T02:39:33.13165Z","shell.execute_reply.started":"2024-07-07T02:39:33.123485Z"},"trusted":true},"outputs":[],"source":["def plot_by_err(df, num_plots):\n","    # Calculate the absolute difference between Column2 and Column3\n","    df['AbsDiff'] = (df['label'] - df['pred']).abs()\n","\n","    # Sort the DataFrame by the absolute difference in descending order\n","    df_sorted = df.sort_values(by='AbsDiff', ascending=False)\n","\n","    # Select the top rows\n","    top_ = df_sorted.head(num_plots)\n","    print(top_)\n","    \n","    fig = plt.figure(figsize=(9,9))\n","    rows, cols = math.ceil(num_plots/3) ,3\n","#     torch.manual_seed(random_seed)\n","    for i in range(num_plots):\n","        top_.iloc[i].values\n","        img_path, label, pred,_ =  top_.iloc[i].values\n","        fig.add_subplot(rows, cols, i+1)\n","        im = Image.open(img_path)\n","        plt.imshow(im)\n","        plt.title(f'label:{label:.4f}|pred:{pred:.4f}')\n","        plt.axis(False)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T02:40:48.492845Z","iopub.status.busy":"2024-07-07T02:40:48.492002Z","iopub.status.idle":"2024-07-07T02:40:50.029533Z","shell.execute_reply":"2024-07-07T02:40:50.028519Z","shell.execute_reply.started":"2024-07-07T02:40:48.49281Z"},"trusted":true},"outputs":[],"source":["plot_by_err(val_pred, 18)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4885061,"sourceId":8237211,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
